{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Science\\DocScan-Research\\envdocscan\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import supervision as sv\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import time\n",
    "import torchvision\n",
    "from torchvision.ops import box_iou\n",
    "import torch\n",
    "import pytorch_lightning\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r'D:\\Data Science\\DocScan-Research\\Inference\\DETR FINAL DATA'\n",
    "ANNOTATION_FILE_NAME = r\"result.json\"\n",
    "TRAIN_DIRECTORY = os.path.join(dataset, r\"train\")\n",
    "VAL_DIRECTORY = os.path.join(dataset, r\"val\")\n",
    "TEST_DIRECTORY = os.path.join(dataset, r\"test\")\n",
    "\n",
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_directory_path: str,\n",
    "        image_processor,\n",
    "        train: bool = True\n",
    "    ):\n",
    "        annotation_file_path = os.path.join(image_directory_path, ANNOTATION_FILE_NAME)\n",
    "        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images, annotations = super(CocoDetection, self).__getitem__(idx)\n",
    "        image_id = self.ids[idx]\n",
    "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
    "        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "\n",
    "        return pixel_values, target\n",
    "    \n",
    "TRAIN_DATASET = CocoDetection(\n",
    "    image_directory_path=TRAIN_DIRECTORY,\n",
    "    image_processor=image_processor,\n",
    "    train=True)\n",
    "VAL_DATASET = CocoDetection(\n",
    "    image_directory_path=VAL_DIRECTORY,\n",
    "    image_processor=image_processor,\n",
    "    train=False)\n",
    "TEST_DATASET = CocoDetection(\n",
    "    image_directory_path=TEST_DIRECTORY,\n",
    "    image_processor=image_processor,\n",
    "    train=False)\n",
    "\n",
    "print(\"Number of training examples:\", len(TRAIN_DATASET))\n",
    "print(\"Number of validation examples:\", len(VAL_DATASET))\n",
    "print(\"Number of test examples:\", len(TEST_DATASET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = \"facebook/detr-resnet-50\"\n",
    "\n",
    "# Best Performing Model\n",
    "MODEL_PATH = \"D:\\Data Science\\DocScan-Research\\Inference\\DETR 11\"\n",
    "\n",
    "\n",
    "## Load Model\n",
    "def loadModel(MODEL_PATH, CHECKPOINT):\n",
    "    model = DetrForObjectDetection.from_pretrained(MODEL_PATH)\n",
    "    image_processor = DetrImageProcessor.from_pretrained(CHECKPOINT)\n",
    "    return model, image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DetrForObjectDetection\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Initialize the model architecture\n",
    "model, image_processor = loadModel(MODEL_PATH=MODEL_PATH, CHECKPOINT=CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"D:\\Data Science\\DocScan-Research\\Inference\\DETR 11\\detr-epoch=99-val_loss=0.90.ckpt\", map_location='cpu')\n",
    "\n",
    "# # Get the state dict\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "# # # Remove the 'model.model.' prefix from the state dict keys\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k.replace(\"model.model.\", \"\")\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "# # # Load the modified state dict\n",
    "model.load_state_dict(new_state_dict, strict=False)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    " \n",
    "def create_ground_truth_dict(json_file_path):\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "   \n",
    "    # Create a mapping of image_id to file_name\n",
    "    image_id_to_filename = {img['id']: img['file_name'] for img in data['images']}\n",
    "   \n",
    "    # Use defaultdict to automatically initialize empty dictionaries for new keys\n",
    "    ground_truth = defaultdict(lambda: {'boxes': [], 'labels': []})\n",
    "   \n",
    "    # Process annotations\n",
    "    for annotation in data['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        filename = image_id_to_filename[image_id]\n",
    "       \n",
    "        # Extract bounding box coordinates\n",
    "        x, y, width, height = annotation['bbox']\n",
    "        box = [x, y, x + width, y + height]\n",
    "       \n",
    "        # Add box and label to the ground_truth dictionary\n",
    "        ground_truth[filename]['boxes'].append(box)\n",
    "        ground_truth[filename]['labels'].append(annotation['category_id'])\n",
    "   \n",
    "    # Convert defaultdict back to regular dict for final output\n",
    "    return dict(ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = r'D:\\Data Science\\DocScan-Research\\Inference\\DETR FINAL DATA\\test\\result.json'\n",
    "ground_truth = create_ground_truth_dict(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = TEST_DATASET.coco.cats\n",
    "id2label = {k: v['name'] for k,v in categories.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id2label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_label(image, save_path, labels):\n",
    "    if labels:  # Only add text if there are missing labels\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        font = ImageFont.load_default()\n",
    "        text = f\"Missing labels: {', '.join(map(str, labels))}\"\n",
    "        position = (10, 10)\n",
    "        draw.text(position, text, fill=\"red\", font=font)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)  # Ensure the directory exists\n",
    "    image.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\Data Science\\DocScan-Research\\ExtractedImages2\\output_folder1.png\n",
      "{0, 1, 2, 3}\n",
      "Processing D:\\Data Science\\DocScan-Research\\ExtractedImages2\\output_folder2.png\n",
      "{0, 1, 2, 3}\n",
      "Processing D:\\Data Science\\DocScan-Research\\ExtractedImages2\\output_folder3.png\n",
      "{0, 1, 2, 3}\n",
      "Processing D:\\Data Science\\DocScan-Research\\ExtractedImages2\\output_folder4.png\n",
      "{0, 2, 3}\n",
      "Processing D:\\Data Science\\DocScan-Research\\ExtractedImages2\\output_folder5.png\n",
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "IMAGE_FOLDER = r'D:\\Data Science\\DocScan-Research\\ExtractedImages2'\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "def inference(image_folder, CONFIDENCE_THRESHOLD, IOU_THRESHOLD):\n",
    "    results_dict = {}\n",
    "    \n",
    "    for img in os.listdir(image_folder):\n",
    "        IMAGE_PATH = os.path.join(image_folder, img)\n",
    "        print(f\"Processing {IMAGE_PATH}\")\n",
    "\n",
    "        image = cv2.imread(IMAGE_PATH)\n",
    "        inputs = image_processor(images=image, return_tensors='pt')\n",
    "\n",
    "        # Move inputs to the same device as the model\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        # Get ground truth for this image\n",
    "        # target = ground_truth.get(img, {'boxes': torch.empty((0, 4)), 'labels': torch.empty((0,), dtype=torch.long)})\n",
    "        # target = {k: v for k, v in target.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Post-process\n",
    "            target_sizes = torch.tensor([image.shape[:2]]).to(model.device)\n",
    "            results = image_processor.post_process_object_detection(\n",
    "                outputs=outputs,\n",
    "                threshold=CONFIDENCE_THRESHOLD,\n",
    "                target_sizes=target_sizes\n",
    "            )[0]\n",
    "        \n",
    "        detections = sv.Detections.from_transformers(transformers_results=results)\n",
    "        id2labels = {0: \"bar-scale\", 1: \"color stamp\", 2: \"detail label\", 3: \"north sign\"}\n",
    "        # labels = [f\"{id2label[class_id]} {confidence:.2f}\" for _, confidence, class_id, _ in detections]\n",
    "        # labels = id2labels\n",
    "        print(set(detections.class_id)) \n",
    "        \n",
    "        box_annotator = sv.BoxAnnotator()\n",
    "        frame = box_annotator.annotate(scene=image, detections=detections)\n",
    "        \n",
    "        image = Image.fromarray(frame)\n",
    "        image_path = f\"Temp3/results/annotated_{img}\"\n",
    "        all_labels = {0, 1, 2, 3}\n",
    "        label = all_labels - set(detections.class_id)\n",
    "        add_missing_label(image, image_path, label) # type: ignore\n",
    "        results_dict[IMAGE_PATH.replace('Temp3/', '')] = results\n",
    "    return results_dict\n",
    "\n",
    "results = inference(IMAGE_FOLDER, CONFIDENCE_THRESHOLD, IOU_THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = inference(IMAGE_FOLDER, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ground_truth))\n",
    "print(type(ground_truth))\n",
    "print(len(results))\n",
    "print(type(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "    \n",
    "    Parameters:\n",
    "    - box1: (x1, y1, x2, y2) coordinates of the first bounding box\n",
    "    - box2: (x1, y1, x2, y2) coordinates of the second bounding box\n",
    "    \n",
    "    Returns:\n",
    "    - iou: Intersection over Union (IoU) value\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack the coordinates of the two boxes\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    # Calculate the (x, y) coordinates of the intersection rectangle\n",
    "    xi1 = max(x1_1, x1_2)\n",
    "    yi1 = max(y1_1, y1_2)\n",
    "    xi2 = min(x2_1, x2_2)\n",
    "    yi2 = min(y2_1, y2_2)\n",
    "    \n",
    "    # Calculate the area of the intersection rectangle\n",
    "    inter_width = max(0, xi2 - xi1)\n",
    "    inter_height = max(0, yi2 - yi1)\n",
    "    inter_area = inter_width * inter_height\n",
    "    \n",
    "    # Calculate the area of both bounding boxes\n",
    "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    \n",
    "    # Calculate the union area\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    # Calculate the IoU\n",
    "    iou = inter_area / union_area if union_area != 0 else 0\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(ground_truth.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth['images/a9720cda-drawing_76.png']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth['images/a9720cda-drawing_76.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['D:\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\a9720cda-drawing_76.png']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['D:\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\a9720cda-drawing_76.png']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIAL AND ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "ground_copy = copy.deepcopy(ground_truth)\n",
    "results_copy = copy.deepcopy(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_copy['images/a9720cda-drawing_76.png']['labels'])\n",
    "print(results_copy['D:\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\a9720cda-drawing_76.png']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ground_truth = ground_copy\n",
    "temp_results = results_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_ground_truth)\n",
    "print(temp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_result(image, ground_truth, results, TP, FP, FN):\n",
    "    result_dict = []\n",
    "    for i in range(len(ground_truth[f'images/{image}']['labels'])):\n",
    "        label = ground_truth[f'images/{image}']['labels'][i]\n",
    "        match = False\n",
    "        for j in range(len(results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'])):\n",
    "            pred_label = results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'][j]\n",
    "            iou = calculate_iou(ground_truth[f'images/{image}']['boxes'][i], results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j])\n",
    "            if iou > 0:\n",
    "                if pred_label == label:\n",
    "                    result_dict.append({'label': label, \n",
    "                                        'iou': iou, \n",
    "                                        'result': 'TP',\n",
    "                                        'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                        'prediction': results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j]\n",
    "                                        })\n",
    "                    results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'][j] = -1\n",
    "                    TP += 1\n",
    "                    match = True\n",
    "                    break\n",
    "                else:\n",
    "                    result_dict.append({'label': label, \n",
    "                                        'iou': iou, \n",
    "                                        'result': 'FP',\n",
    "                                        'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                        'prediction': results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j]\n",
    "                                        })\n",
    "                    FP += 1\n",
    "                    match = True\n",
    "            \n",
    "        if not match:\n",
    "            result_dict.append({'label': label, \n",
    "                                'iou': 0, \n",
    "                                'result': 'FN',\n",
    "                                'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                'prediction': []\n",
    "                                })\n",
    "            FN += 1\n",
    "                \n",
    "    return result_dict, TP, FP, FN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, FN = 0, 0, 0\n",
    "result_dict, TP, FP, FN = final_result('1eecb4f3-drawing_25.png', temp_ground_truth, temp_results, TP, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On all the images at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_result(image, ground_truth, results, TP, FP, FN):\n",
    "    result_dict = []\n",
    "    for i in range(len(ground_truth[f'images/{image}']['labels'])):\n",
    "        label = ground_truth[f'images/{image}']['labels'][i]\n",
    "        match = False\n",
    "        for j in range(len(results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'])):\n",
    "            pred_label = results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'][j]\n",
    "            iou = calculate_iou(ground_truth[f'images/{image}']['boxes'][i], results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j])\n",
    "            if iou > 0:\n",
    "                if pred_label == label:\n",
    "                    result_dict.append({'label': label, \n",
    "                                        'iou': iou, \n",
    "                                        'result': 'TP',\n",
    "                                        'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                        'prediction': results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j]\n",
    "                                        })\n",
    "                    results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'][j] = -1\n",
    "                    TP += 1\n",
    "                    match = True\n",
    "                    break\n",
    "                else:\n",
    "                    result_dict.append({'label': label, \n",
    "                                        'iou': iou, \n",
    "                                        'result': 'FP',\n",
    "                                        'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                        'prediction': results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j]\n",
    "                                        })\n",
    "                    FP += 1\n",
    "                    match = True\n",
    "            \n",
    "        if not match:\n",
    "            result_dict.append({'label': label, \n",
    "                                'iou': 0, \n",
    "                                'result': 'FN',\n",
    "                                'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                'prediction': []\n",
    "                                })\n",
    "            FN += 1\n",
    "                \n",
    "    return result_dict, TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_images(ground_truth, results):\n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    all_results = []\n",
    "    \n",
    "    for image in ground_truth.keys():\n",
    "        image = image.split('/')[-1]\n",
    "        result_dict, TP, FP, FN = final_result(image, temp_ground_truth, temp_results, TP, FP, FN)\n",
    "        all_results.extend(result_dict)\n",
    "    \n",
    "    return all_results, TP, FP, FN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results, TP, FP, FN = evaluate_all_images(temp_ground_truth, temp_results)\n",
    "\n",
    "print(f'Total True Positives (TP): {TP}')\n",
    "print(f'Total False Positives (FP): {FP}')\n",
    "print(f'Total False Negatives (FN): {FN}')\n",
    "print('Detailed results for each box:')\n",
    "for result in all_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEL WISE TP ,FP ,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# def calculate_iou(box1, box2):\n",
    "#     x1, y1, x2, y2 = box1\n",
    "#     x1_p, y1_p, x2_p, y2_p = box2\n",
    "\n",
    "#     xi1, yi1 = max(x1, x1_p), max(y1, y1_p)\n",
    "#     xi2, yi2 = min(x2, x2_p), min(y2, y2_p)\n",
    "#     inter_area = max(0, xi2 - xi1 + 1) * max(0, yi2 - yi1 + 1)\n",
    "\n",
    "#     box1_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "#     box2_area = (x2_p - x1_p + 1) * (y2_p - y1_p + 1)\n",
    "#     union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "#     iou = inter_area / union_area\n",
    "#     return iou\n",
    "\n",
    "def final_result(image, ground_truth, results, TP, FP, FN, class_TP, class_FP, class_FN):\n",
    "    result_dict = []\n",
    "    for i in range(len(ground_truth[f'images/{image}']['labels'])):\n",
    "        label = ground_truth[f'images/{image}']['labels'][i]\n",
    "        match = False\n",
    "        for j in range(len(results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'])):\n",
    "            pred_label = results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'][j]\n",
    "            iou = calculate_iou(ground_truth[f'images/{image}']['boxes'][i], results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j])\n",
    "            if iou > 0:\n",
    "                if pred_label == label:\n",
    "                    result_dict.append({'label': label, \n",
    "                                        'iou': iou, \n",
    "                                        'result': 'TP',\n",
    "                                        'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                        'prediction': results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j]\n",
    "                                        })\n",
    "                    results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['labels'][j] = -1\n",
    "                    TP += 1\n",
    "                    class_TP[label] += 1\n",
    "                    match = True\n",
    "                    break\n",
    "                else:\n",
    "                    result_dict.append({'label': label, \n",
    "                                        'iou': iou, \n",
    "                                        'result': 'FP',\n",
    "                                        'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                        'prediction': results[f'D:\\\\Data Science\\\\DocScan-Research\\\\Inference\\\\DETR FINAL DATA\\\\test\\\\images\\\\{image}']['boxes'][j]\n",
    "                                        })\n",
    "                    FP += 1\n",
    "                    class_FP[label] += 1\n",
    "                    match = True\n",
    "            \n",
    "        if not match:\n",
    "            result_dict.append({'label': label, \n",
    "                                'iou': 0, \n",
    "                                'result': 'FN',\n",
    "                                'ground_truth': ground_truth[f'images/{image}']['boxes'][i],\n",
    "                                'prediction': []\n",
    "                                })\n",
    "            FN += 1\n",
    "            class_FN[label] += 1\n",
    "                \n",
    "    return result_dict, TP, FP, FN, class_TP, class_FP, class_FN\n",
    "\n",
    "def evaluate_all_images(ground_truth, results):\n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    class_TP, class_FP, class_FN = defaultdict(int), defaultdict(int), defaultdict(int)\n",
    "    all_results = []\n",
    "    \n",
    "    for image in ground_truth.keys():\n",
    "        image = image.split('/')[-1]\n",
    "        result_dict, TP, FP, FN, class_TP, class_FP, class_FN = final_result(image, ground_truth, results, TP, FP, FN, class_TP, class_FP, class_FN)\n",
    "        all_results.extend(result_dict)\n",
    "    \n",
    "    return all_results, TP, FP, FN, class_TP, class_FP, class_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results, TP, FP, FN, class_TP, class_FP, class_FN = evaluate_all_images(ground_truth, results)\n",
    "\n",
    "print(f'Total TP: {TP}, Total FP: {FP}, Total FN: {FN}')\n",
    "print(f'Class-wise TP: {dict(class_TP)}, Class-wise FP: {dict(class_FP)}, Class-wise FN: {dict(class_FN)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envdocscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
